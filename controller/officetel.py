from selenium import webdriver as wb
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import StackingRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error, r2_score
from lightgbm import LGBMRegressor
import re
from datetime import datetime
from tqdm import tqdm
from selenium.common.exceptions import NoSuchElementException, WebDriverException, ElementNotInteractableException
import psycopg
import psycopg_pool
import joblib
import os
import shap
from xgboost import XGBRegressor
from catboost import CatBoostRegressor
from selenium.webdriver.chrome.options import Options

# pip install selenium pandas numpy tqdm scikit-learn lightgbm

options = Options()
options.add_argument('--headless=new')  # ìƒˆë¡œìš´ Headless ëª¨ë“œ (êµ¬ë²„ì „ë³´ë‹¤ ì•ˆì •ì )
options.add_argument('--no-sandbox')
options.add_argument('--disable-dev-shm-usage')
options.add_argument('--disable-gpu')  # GPU ë Œë”ë§ ì´ìŠˆ ë°©ì§€
options.add_argument('--window-size=1920,1080')  # ë·°í¬íŠ¸ ì‚¬ì´ì¦ˆ ì„¤ì •
options.add_argument('--disable-blink-features=AutomationControlled')  # ìë™í™” ê°ì§€ ë°©ì§€
options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36')

# í¬ë¡¬ ë“œë¼ì´ë²„ ì‹¤í–‰
driver = wb.Chrome(options=options)
url = 'https://www.dabangapp.com/map/officetel?m_lat=35.1464492&m_lng=126.8851831&m_zoom=12'
driver.get(url)
time.sleep(2)

# ë§í¬ ìˆ˜ì§‘ ë¦¬ìŠ¤íŠ¸
href_list = []
MAX_PAGES = 40  # í˜ì´ì§€ ê°œìˆ˜ ì œí•œ (í•„ìš”ì‹œ ì¡°ì ˆ)

for page in range(MAX_PAGES):
    print(f"\nğŸ“„ {page+1} í˜ì´ì§€ ìˆ˜ì§‘ ì¤‘...")

    # âœ… ë¦¬ìŠ¤íŠ¸ ì˜ì—­ ìŠ¤í¬ë¡¤ (ì˜ˆì™¸ ì²˜ë¦¬ ì¶”ê°€)
    try:
        body = WebDriverWait(driver, 5).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, '#officetel-list'))
        )
        if not body.is_displayed():
            print("ğŸš« ë¦¬ìŠ¤íŠ¸ ì˜ì—­ì´ í™”ë©´ì— ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤. í¬ë¡¤ë§ ì¢…ë£Œ.")
            break

        for _ in range(3):
            try:
                body.send_keys(Keys.END)
                time.sleep(0.5)
            except ElementNotInteractableException as e:
                print(f"âŒ body ìš”ì†Œê°€ ìƒí˜¸ì‘ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤. {e}")
                break

    except Exception as e:
        print(f"âŒ ë¦¬ìŠ¤íŠ¸ ìŠ¤í¬ë¡¤ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        break

    WebDriverWait(driver, 10).until(
        EC.presence_of_all_elements_located((By.CSS_SELECTOR, '#officetel-list li'))
    )

    items = driver.find_elements(By.CSS_SELECTOR, '#officetel-list li')
    print(f"â–¶ {len(items)}ê°œ í•­ëª© ë°œê²¬")

    for i in range(len(items)):
        try:
            items = driver.find_elements(By.CSS_SELECTOR, '#officetel-list li')
            item = items[i]

            driver.execute_script("arguments[0].scrollIntoView(true);", item)
            time.sleep(0.2)
            WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.CSS_SELECTOR, '#officetel-list li')))
            driver.execute_script("arguments[0].click();", item)
            time.sleep(0.5)

            current_url = driver.current_url
            if 'detail_type=room' in current_url and 'detail_id=' in current_url:
                if current_url not in href_list:
                    href_list.append(current_url)

        except Exception as e:
            print(f"{i}ë²ˆì§¸ í•­ëª© í´ë¦­ ì‹¤íŒ¨: {e}")

    # ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ í´ë¦­ ì‹œë„
    try:
        next_button = driver.find_element(By.CSS_SELECTOR, 'button[aria-label="ë‹¤ìŒ í˜ì´ì§€"]')
        driver.execute_script("arguments[0].click();", next_button)
        time.sleep(2)
    except:
        print("ğŸš« ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ì´ ì—†ê±°ë‚˜ ë” ì´ìƒ í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        break

# ê²°ê³¼ ì¶œë ¥
print(f"\n ì´ ìˆ˜ì§‘ëœ ë§í¬ ìˆ˜: {len(href_list)}")
for link in href_list:
    print(link)

# ë§í¬ë¥¼ CSVë¡œ ì €ì¥
df = pd.DataFrame(href_list, columns=["URL"])
df.to_csv("ë‹¤ë°©_ê´‘ì£¼_ë§í¬_ì˜¤í”¼ìŠ¤í…”.csv", index=False)
print("\nğŸ’¾ ë§í¬ ì €ì¥ ì™„ë£Œ: ë‹¤ë°©_ê´‘ì£¼_ë§í¬_ì˜¤í”¼ìŠ¤í…”.csv")

driver.quit()

# ì˜µì…˜, ì¤‘ê°œì‚¬ë¬´ì†Œëª…, ì£¼ì†Œì‹œë„, ê³µê¸‰, ì‚¬ìš©ë©´ì  í•©ì¹¨, ì—˜ë¦¬ë² ì´í„° ì—†ìŒ ëœ¨ê¸°


# í¬ë¡¬ ë“œë¼ì´ë²„ ì‹¤í–‰
driver = wb.Chrome(options=options)

# ë§í¬ ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv("ë‹¤ë°©_ê´‘ì£¼_ë§í¬_ì˜¤í”¼ìŠ¤í…”.csv")
href_list = df['URL'].tolist()

# ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
data_rows = []

for i in tqdm(range(len(href_list))):
    print(f"\nğŸ”— {i+1}/{len(href_list)} ë²ˆì§¸ ë§í¬ ì ‘ê·¼ ì¤‘...\nURL: {href_list[i]}")
    row_data = {"URL": href_list[i]}

    try:
        driver.get(href_list[i])
        time.sleep(0.8)

        #  ê°€ê²©ì •ë³´ ìˆ˜ì§‘
        try:
            price_items = driver.find_elements(By.CSS_SELECTOR, 'section[data-scroll-spy-element="price-info"] li')
            for item in price_items:
                try:
                    key = item.find_element(By.TAG_NAME, 'h1').text.strip()
                    value = item.find_element(By.TAG_NAME, 'p').text.strip()
                    row_data[key] = value
                except:
                    continue
        except:
            print("âš ï¸ ê°€ê²©ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨")

        # ìƒì„¸ì •ë³´ ìˆ˜ì§‘ (ì „ìš©ë©´ì ë§Œ ìˆ˜ì§‘ + ì—˜ë¦¬ë² ì´í„° ì—†ì„ ì‹œ 'ì—†ìŒ' ì²˜ë¦¬ + í•­ëª© ë¶„ë¦¬)
        try:
            detail_items = driver.find_elements(By.CSS_SELECTOR, 'section[data-scroll-spy-element="detail-info"] li')
            for item in detail_items:
                try:
                    key = item.find_element(By.TAG_NAME, 'h1').text.strip()
                    value = item.find_element(By.TAG_NAME, 'p').text.strip()

                    # ì „ìš©/ê³µê¸‰ë©´ì  ë˜ëŠ” ì „ìš©/ê³„ì•½ë©´ì  â†’ ì „ìš©ë§Œ ìˆ˜ì§‘
                    if ("ì „ìš©/ê³µê¸‰ë©´ì " in key or "ì „ìš©/ê³„ì•½ë©´ì " in key) and "/" in value:
                        ì „ìš© = value.split("/")[0].strip()
                        row_data["ì „ìš©ë©´ì "] = ì „ìš©

                    # ë°© ìˆ˜ / ìš•ì‹¤ ìˆ˜ ë¶„ë¦¬
                    elif "ë°© ìˆ˜/ìš•ì‹¤ ìˆ˜" in key and "/" in value:
                        parts = value.split("/")
                        row_data["ë°© ìˆ˜"] = parts[0].strip()
                        row_data["ìš•ì‹¤ ìˆ˜"] = parts[1].strip()

                    # í•´ë‹¹ì¸µ / ê±´ë¬¼ì¸µ ë¶„ë¦¬
                    elif "í•´ë‹¹ì¸µ/ê±´ë¬¼ì¸µ" in key and "/" in value:
                        parts = value.split("/")
                        row_data["í•´ë‹¹ì¸µ"] = parts[0].strip()
                        row_data["ê±´ë¬¼ì¸µ"] = parts[1].strip()

                    else:
                        row_data[key] = value
                except:
                    continue

            # ì—˜ë¦¬ë² ì´í„° í•­ëª© ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ 'ì—†ìŒ' ë„£ê¸°
            if "ì—˜ë¦¬ë² ì´í„°" not in row_data:
                row_data["ì—˜ë¦¬ë² ì´í„°"] = "ì—†ìŒ"

        except:
            print("âš ï¸ ìƒì„¸ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨")




        # ì˜µì…˜ ì •ë³´ ìˆ˜ì§‘
        try:
            option_section = driver.find_element(By.CSS_SELECTOR, 'div[data-scroll-spy-element="options"]')
            option_tags = option_section.find_elements(By.TAG_NAME, 'p')
            options = [opt.text.strip() for opt in option_tags if opt.text.strip()]
            row_data["ì˜µì…˜ì •ë³´"] = ", ".join(options)
        except:
            print("âš ï¸ ì˜µì…˜ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨")

        # ì¤‘ê°œì‚¬ë¬´ì†Œ ì •ë³´ ìˆ˜ì§‘
        try:
            office_name = driver.find_element(By.CSS_SELECTOR, 'section[data-scroll-spy-element="agent-info"] div h1').text.strip()
            row_data["ì¤‘ê°œì‚¬ë¬´ì†Œëª…"] = office_name
        except:
            print("âš ï¸ ì¤‘ê°œì‚¬ë¬´ì†Œëª… ìˆ˜ì§‘ ì‹¤íŒ¨")

        # ë§¤ë¬¼ ìœ„ì¹˜ ì£¼ì†Œ ìˆ˜ì§‘ (JavaScript + Wait)


        try:
            address_element = WebDriverWait(driver, 5).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, 'section[data-scroll-spy-element="near"] p'))
        )
            address_text = driver.execute_script("return arguments[0].innerText;", address_element).strip()
            row_data["ë§¤ë¬¼ì£¼ì†Œ"] = address_text
        except:
            print("âš ï¸ ë§¤ë¬¼ ì£¼ì†Œ ìˆ˜ì§‘ ì‹¤íŒ¨ (JS í™œìš©)")

    


    except WebDriverException:
        print(f"[âŒ ì˜¤ë¥˜] ì›¹ ë“œë¼ì´ë²„ ë¬¸ì œ ë°œìƒ: {href_list[i]}")
    except Exception as e:
        print(f"[âŒ ì˜¤ë¥˜] ì•Œ ìˆ˜ ì—†ëŠ” ë¬¸ì œ ë°œìƒ: {href_list[i]} - {e}")

    data_rows.append(row_data)
    time.sleep(0.3)

driver.quit()
print("\n ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ!")

# ê²°ê³¼ ì €ì¥
result_df = pd.DataFrame(data_rows)
result_df.to_csv("ë‹¤ë°©_ê´‘ì£¼_ì˜¤í”¼ìŠ¤í…”.csv", index=False)
print("ğŸ’¾ ì €ì¥ ì™„ë£Œ: ë‹¤ë°©_ê´‘ì£¼_ì˜¤í”¼ìŠ¤í…”.csv")

# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
file_path = 'ë‹¤ë°©_ê´‘ì£¼_ì˜¤í”¼ìŠ¤í…”.csv'
df = pd.read_csv(file_path)

#  'ë§¤ë§¤' ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ í•„í„°ë§
if 'ë§¤ë§¤' in df.columns:
    df = df[df['ë§¤ë§¤'].isna() | (df['ë§¤ë§¤'].astype(str).str.strip() == '')]
else:
    print("âš ï¸ 'ë§¤ë§¤' ì»¬ëŸ¼ì´ ì—†ì–´ í•„í„°ë§ì„ ê±´ë„ˆëœë‹ˆë‹¤.")

# 'ê¸° ë³´ì¦ê¸ˆ/ì›”ì„¸' ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ í•„í„°ë§
if 'ê¸° ë³´ì¦ê¸ˆ/ì›”ì„¸' in df.columns:
    df = df[df['ê¸° ë³´ì¦ê¸ˆ/ì›”ì„¸'].isna() | (df['ê¸° ë³´ì¦ê¸ˆ/ì›”ì„¸'].astype(str).str.strip() == '')]
else:
    print("âš ï¸ 'ê¸° ë³´ì¦ê¸ˆ/ì›”ì„¸' ì»¬ëŸ¼ì´ ì—†ì–´ í•„í„°ë§ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
# ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ëŠ” ê²½ìš°ì—ë§Œ ì‚­ì œ
columns_to_drop = [
    'í•œë‹¬\nì˜ˆìƒ ì£¼ê±°ë¹„ìš©', 'ê±´ë¬¼ì´ë¦„', 'ë‚œë°©ì¢…ë¥˜', 'í•´ë‹¹ ë©´ì \nì„¸ëŒ€ ìˆ˜', 'ì´ ì„¸ëŒ€ìˆ˜', 
                'ì´ ì£¼ì°¨ëŒ€ìˆ˜', 'ì„¸ëŒ€ë‹¹ ì£¼ì°¨ìˆ˜', 'í˜„ê´€ìœ í˜•','ìœµìê¸ˆ', 'ë³µì¸µì—¬ë¶€', 'ë§¤ë§¤', 'ê¸° ë³´ì¦ê¸ˆ/ì›”ì„¸',
                'LH ì „ì„¸ì„ëŒ€', 'ì¤€ê³µì¸ê°€ì¼' 
]
actual_columns_to_drop = [col for col in columns_to_drop if col in df.columns]
df.drop(columns=actual_columns_to_drop, inplace=True)

# 'ì „ìš©ë©´ì ' ì»¬ëŸ¼ì— ê°’ì´ ì—†ëŠ” í–‰ ì œê±°
df = df[~df['ì „ìš©ë©´ì '].isna() & (df['ì „ìš©ë©´ì '].astype(str).str.strip() != '')]
# 'ì£¼ì°¨ê°€ëŠ¥ì—¬ë¶€' ì»¬ëŸ¼ì— ê°’ì´ ì—†ëŠ” í–‰ ì œê±°
df = df[~df['ì‚¬ìš©ìŠ¹ì¸ì¼'].isna() & (df['ì‚¬ìš©ìŠ¹ì¸ì¼'].astype(str).str.strip() != '')]
# 'ë§¤ë¬¼ì£¼ì†Œ'ì— ì¤‘ê°œë¼ê³  ë“¤ì–´ê°„ í–‰ ì œê±°
df = df[~df['ë§¤ë¬¼ì£¼ì†Œ'].astype(str).str.contains('ì¤‘ê°œ', na=False)]
# ë§¤ë¬¼ì£¼ì†Œì— 'ê´‘ì£¼'ê°€ ì•ˆ ì í˜€ìˆëŠ” í–‰ ì œê±° 
df = df[df['ë§¤ë¬¼ì£¼ì†Œ'].astype(str).str.contains('ê´‘ì£¼', na=False)]

# ë‚ ì§œ í˜•ì‹ìœ¼ë¡œ ì˜ëª» ë“¤ì–´ê°„ ì›”ì„¸ ì œê±°
df['ì›”ì„¸'] = df['ì›”ì„¸'].astype(str).str.strip()
df = df[~df['ì›”ì„¸'].str.match(r'^[A-Za-z]{3}-\d{2}$', na=False)]

def convert_price(text):
    if pd.isna(text):
        return None
    text = str(text).replace(',', '').strip()

    # "1ì–µ1000" ê°™ì€ í˜•ì‹ ì²˜ë¦¬
    if 'ì–µ' in text:
        match = re.match(r'(\d+)ì–µ(\d+)?', text)
        if match:
            ì–µ = int(match.group(1)) * 10000
            ì²œ = int(match.group(2)) if match.group(2) else 0
            return ì–µ + ì²œ
    elif text.isdigit():
        return int(text)
    else:
        return None

# ë‚˜ëˆ„ê¸°
df[['ì›”ì„¸ë³´ì¦ê¸ˆ', 'ì›”ì„¸ê°€ê²©']] = df['ì›”ì„¸'].str.split('/', expand=True)

# ìˆ«ì ë³€í™˜
df['ì›”ì„¸ë³´ì¦ê¸ˆ'] = df['ì›”ì„¸ë³´ì¦ê¸ˆ'].apply(convert_price)
df['ì›”ì„¸ê°€ê²©'] = pd.to_numeric(df['ì›”ì„¸ê°€ê²©'], errors='coerce')  # ì›”ì„¸ëŠ” ë³´í†µ ìˆ«ìì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì²˜ë¦¬


columns_to_drop = ['ì›”ì„¸']

# ì»¬ëŸ¼ ì‚­ì œ
df.drop(columns=columns_to_drop, inplace=True)

df['ì „ì„¸_ì—¬ë¶€'] = df['ì „ì„¸'].apply(lambda x: 'O' if pd.notnull(x) and str(x).strip() != '' else 'X')

# ë§¤ë¬¼ ë°ì´í„°ì—ì„œ 'êµ¬'ì™€ 'ë²•ì •ë™' ë½‘ê¸°
def extract_gu(address):
    if pd.isna(address):
        return None
    parts = address.split()
    for part in parts:
        if part.endswith('êµ¬'):
            return part
    return None

def extract_dong(address):
    if pd.isna(address):
        return None
    parts = address.split()
    for part in parts:
        if part.endswith(('ë™', 'ê°€')):
            return part
    return None

df['êµ¬'] = df['ë§¤ë¬¼ì£¼ì†Œ'].apply(extract_gu)
df['ë²•ì •ë™'] = df['ë§¤ë¬¼ì£¼ì†Œ'].apply(extract_dong)

# ê´‘ì£¼ê´‘ì—­ì‹œ ì „ì²´ í–‰ì •ë™-ë²•ì •ë™ ë§¤í•‘í‘œ (5ê°œ ì§€ì—­êµ¬ ê¸°ì¤€ ì™„ì„±)
ê´‘ì£¼_í–‰ì •ë™_ë²•ì •ë™_ë§¤í•‘ = {
    # ë™êµ¬
    ("ë™êµ¬", "ì¶©ì¥ë™"): ["ì¶©ì¥ë¡œ1ê°€", "ì¶©ì¥ë¡œ2ê°€", "ì¶©ì¥ë¡œ3ê°€", "ì¶©ì¥ë¡œ4ê°€", "ì¶©ì¥ë¡œ5ê°€", "ê¸ˆë‚¨ë¡œ1ê°€", "ê¸ˆë‚¨ë¡œ2ê°€", "ê¸ˆë‚¨ë¡œ3ê°€", "ê¸ˆë‚¨ë¡œ4ê°€", "ê¸ˆë‚¨ë¡œ5ê°€", "ëŒ€ì¸ë™", "ìˆ˜ê¸°ë™", "ê¶ë™", "ëŒ€ì˜ë™", "ì¥ë™", "ë¶ˆë¡œë™", "í˜¸ë‚¨ë™", "í™©ê¸ˆë™"],
    ("ë™êµ¬", "ë™ëª…ë™"): ["ë™ëª…ë™"],
    ("ë™êµ¬", "ê³„ë¦¼1ë™"): ["ê³„ë¦¼ë™"],
    ("ë™êµ¬", "ê³„ë¦¼2ë™"): ["ê³„ë¦¼ë™"],
    ("ë™êµ¬", "ì‚°ìˆ˜1ë™"): ["ì‚°ìˆ˜ë™"],
    ("ë™êµ¬", "ì‚°ìˆ˜2ë™"): ["ì‚°ìˆ˜ë™"],
    ("ë™êµ¬", "ì§€ì‚°1ë™"): ["ì§€ì‚°ë™"],
    ("ë™êµ¬", "ì§€ì‚°2ë™"): ["ì§€ì‚°ë™"],
    ("ë™êµ¬", "ì„œë‚¨ë™"): ["ì„œì„ë™", "ë‚¨ë™", "ê´‘ì‚°ë™", "ê¸ˆë™", "ë¶ˆë¡œë™", "ì¥ë™", "í•™ë™"],
    ("ë™êµ¬", "í•™ë™"): ["í•™ë™"],
    ("ë™êµ¬", "í•™ìš´ë™"): ["í•™ë™", "ìš´ë¦¼ë™"],
    ("ë™êµ¬", "ì§€ì›1ë™"): ["ì†Œíƒœë™", "ìš©ì‚°ë™"],
    ("ë™êµ¬", "ì§€ì›2ë™"): ["ì†Œíƒœë™", "ìš©ì—°ë™", "ì›”ë‚¨ë™", "ì„ êµë™", "ë‚´ë‚¨ë™", "ìš©ì‚°ë™"],

    # ì„œêµ¬
    ("ì„œêµ¬", "ì–‘ë™"): ["ì–‘ë™"],
    ("ì„œêµ¬", "ì–‘3ë™"): ["ì–‘ë™"],
    ("ì„œêµ¬", "ë†ì„±1ë™"): ["ë†ì„±ë™"],
    ("ì„œêµ¬", "ë†ì„±2ë™"): ["ë†ì„±ë™"],
    ("ì„œêµ¬", "ê´‘ì²œë™"): ["ê´‘ì²œë™"],
    ("ì„œêµ¬", "ìœ ë•ë™"): ["ìœ ì´Œë™", "ë•í¥ë™", "ì¹˜í‰ë™", "ìŒì´Œë™", "ë‚´ë°©ë™"],
    ("ì„œêµ¬", "ì¹˜í‰ë™"): ["ì¹˜í‰ë™", "ìŒì´Œë™"],
    ("ì„œêµ¬", "ìƒë¬´1ë™"): ["ìŒì´Œë™", "ì¹˜í‰ë™"],
    ("ì„œêµ¬", "ìƒë¬´2ë™"): ["ìŒì´Œë™", "ì¹˜í‰ë™"],
    ("ì„œêµ¬", "í™”ì •1ë™"): ["í™”ì •ë™", "ë‚´ë°©ë™"],
    ("ì„œêµ¬", "í™”ì •2ë™"): ["í™”ì •ë™"],
    ("ì„œêµ¬", "í™”ì •3ë™"): ["í™”ì •ë™"],
    ("ì„œêµ¬", "í™”ì •4ë™"): ["í™”ì •ë™"],
    ("ì„œêµ¬", "ì„œì°½ë™"): ["ì„¸í•˜ë™", "ìš©ë‘ë™", "ì„œì°½ë™", "ë²½ì§„ë™", "ë§¤ì›”ë™", "ë§ˆë¥µë™"],
    ("ì„œêµ¬", "ê¸ˆí˜¸1ë™"): ["ê¸ˆí˜¸ë™"],
    ("ì„œêµ¬", "ê¸ˆí˜¸2ë™"): ["ê¸ˆí˜¸ë™"],
    ("ì„œêµ¬", "í’ì•”ë™"): ["í’ì•”ë™"],
    ("ì„œêµ¬", "ë™ì²œë™"): ["ë™ì²œë™"],

    # ë‚¨êµ¬
    ("ë‚¨êµ¬", "ì–‘ë¦¼ë™"): ["ì–‘ë¦¼ë™"],
    ("ë‚¨êµ¬", "ë°©ë¦¼1ë™"): ["ë°©ë¦¼ë™"],
    ("ë‚¨êµ¬", "ë°©ë¦¼2ë™"): ["ë°©ë¦¼ë™"],
    ("ë‚¨êµ¬", "ë´‰ì„ 1ë™"): ["ë´‰ì„ ë™"],
    ("ë‚¨êµ¬", "ë´‰ì„ 2ë™"): ["ë´‰ì„ ë™"],
    ("ë‚¨êµ¬", "ì‚¬ì§ë™"): ["ì‚¬ë™", "êµ¬ë™", "ì„œë™"],
    ("ë‚¨êµ¬", "ì›”ì‚°ë™"): ["ì›”ì‚°ë™"],
    ("ë‚¨êµ¬", "ì›”ì‚°4ë™"): ["ì›”ì‚°ë™"],
    ("ë‚¨êµ¬", "ì›”ì‚°5ë™"): ["ì›”ì‚°ë™"],
    ("ë‚¨êµ¬", "ë°±ìš´1ë™"): ["ë°±ìš´ë™"],
    ("ë‚¨êµ¬", "ë°±ìš´2ë™"): ["ë°±ìš´ë™"],
    ("ë‚¨êµ¬", "ì£¼ì›”1ë™"): ["ì£¼ì›”ë™"],
    ("ë‚¨êµ¬", "ì£¼ì›”2ë™"): ["ì£¼ì›”ë™", "ì›”ì‚°ë™", "ë°±ìš´ë™"],
    ("ë‚¨êµ¬", "íš¨ë•ë™"): ["ë…¸ëŒ€ë™", "ë•ë‚¨ë™"],
    ("ë‚¨êµ¬", "ì§„ì›”ë™"): ["ì§„ì›”ë™"],
    ("ë‚¨êµ¬", "ì†¡ì•”ë™"): ["ì†¡í•˜ë™", "ì„ì•”ë™", "í–‰ì•”ë™"],
    ("ë‚¨êµ¬", "ëŒ€ì´Œë™"): ["ì–‘ê³¼ë™", "ì›ì‚°ë™", "ì´ì¥ë™", "ì••ì´Œë™", "ë„ê¸ˆë™", "ì§€ì„ë™", "ì„ì •ë™", "ëŒ€ì§€ë™", "ì¹ ì„ë™", "í™”ì¥ë™", "ì›”ì„±ë™", "ì‹ ì¥ë™", "êµ¬ì†Œë™", "ì–‘ì´Œë™", "ìŠ¹ì´Œë™"],

    # ë¶êµ¬
    ("ë¶êµ¬", "ì¤‘í¥ë™"): ["ì¤‘í¥ë™"],
    ("ë¶êµ¬", "ì¤‘í¥1ë™"): ["ì¤‘í¥ë™"],
    ("ë¶êµ¬", "ì¤‘ì•™ë™"): ["ìœ ë™", "ëˆ„ë¬¸ë™", "ë¶ë™", "ì¤‘í¥ë™"],
    ("ë¶êµ¬", "ì„ë™"): ["ì„ë™"],
    ("ë¶êµ¬", "ì‹ ì•ˆë™"): ["ì‹ ì•ˆë™"],
    ("ë¶êµ¬", "ìš©ë´‰ë™"): ["ìš©ë´‰ë™"],
    ("ë¶êµ¬", "ìš´ì•”1ë™"): ["ìš´ì•”ë™"],
    ("ë¶êµ¬", "ìš´ì•”2ë™"): ["ìš´ì•”ë™"],
    ("ë¶êµ¬", "ìš´ì•”3ë™"): ["ìš´ì•”ë™"],
    ("ë¶êµ¬", "ë™ë¦¼ë™"): ["ë™ë¦¼ë™"],
    ("ë¶êµ¬", "ìš°ì‚°ë™"): ["ìš°ì‚°ë™"],
    ("ë¶êµ¬", "í’í–¥ë™"): ["í’í–¥ë™"],
    ("ë¶êµ¬", "ë¬¸í™”ë™"): ["ê°í™”ë™", "ë¬¸í¥ë™"],
    ("ë¶êµ¬", "ë¬¸í¥1ë™"): ["ë¬¸í¥ë™"],
    ("ë¶êµ¬", "ë¬¸í¥2ë™"): ["ë¬¸í¥ë™"],
    ("ë¶êµ¬", "ë‘ì•”1ë™"): ["ë‘ì•”ë™"],
    ("ë¶êµ¬", "ë‘ì•”2ë™"): ["ë‘ì•”ë™"],
    ("ë¶êµ¬", "ë‘ì•”3ë™"): ["ë‘ì•”ë™"],
    ("ë¶êµ¬", "ì‚¼ê°ë™"): ["ì‚¼ê°ë™"],
    ("ë¶êµ¬", "ì¼ê³¡ë™"): ["ì¼ê³¡ë™"],
    ("ë¶êµ¬", "ë§¤ê³¡ë™"): ["ë§¤ê³¡ë™"],
    ("ë¶êµ¬", "ì˜¤ì¹˜1ë™"): ["ì˜¤ì¹˜ë™"],
    ("ë¶êµ¬", "ì˜¤ì¹˜2ë™"): ["ì˜¤ì¹˜ë™"],
    ("ë¶êµ¬", "ì„ê³¡ë™"): ["ì¶©íš¨ë™", "ë•ì˜ë™", "ê¸ˆê³¡ë™", "ë§ì›”ë™", "ì²­í’ë™", "í™”ì•”ë™", "ì¥ë“±ë™", "ìš´ì •ë™"],
    ("ë¶êµ¬", "ê±´êµ­ë™"): ["ë³¸ì´Œë™", "ìš©ë‘ë™", "ì§€ì•¼ë™", "íƒœë ¹ë™", "ìˆ˜ê³¡ë™", "íš¨ë ¹ë™", "ìš©ì „ë™", "ìš©ê°•ë™", "ìƒìš©ë™", "ì›”ì¶œë™", "ëŒ€ì´Œë™", "ì˜¤ë£¡ë™"],
    ("ë¶êµ¬", "ì–‘ì‚°ë™"): ["ì–‘ì‚°ë™", "ì—°ì œë™", "ì¼ê³¡ë™"],
    ("ë¶êµ¬", "ì‹ ìš©ë™"): ["ì‹ ìš©ë™"],

    # ê´‘ì‚°êµ¬
    ("ê´‘ì‚°êµ¬", "ì†¡ì •1ë™"): ["ì†¡ì •ë™"],
    ("ê´‘ì‚°êµ¬", "ì†¡ì •2ë™"): ["ì†¡ì •ë™"],
    ("ê´‘ì‚°êµ¬", "ë„ì‚°ë™"): ["ë„ì‚°ë™", "í™©ë£¡ë™"],
    ("ê´‘ì‚°êµ¬", "ì‹ í¥ë™"): ["ì‹ ì´Œë™", "ë„í˜¸ë™"],
    ("ê´‘ì‚°êµ¬", "ì–´ë£¡ë™"): ["ë°•í˜¸ë™", "ì„œë´‰ë™", "ì„ ì•”ë™", "ìš´ìˆ˜ë™", "ì†Œì´Œë™"],
    ("ê´‘ì‚°êµ¬", "ìš°ì‚°ë™"): ["ìš°ì‚°ë™"],
    ("ê´‘ì‚°êµ¬", "ì›”ê³¡1ë™"): ["ì›”ê³¡ë™"],
    ("ê´‘ì‚°êµ¬", "ì›”ê³¡2ë™"): ["ì›”ê³¡ë™", "ì‚°ì •ë™"],
    ("ê´‘ì‚°êµ¬", "ë¹„ì•„ë™"): ["ë¹„ì•„ë™", "ë„ì²œë™", "ìˆ˜ì™„ë™"],
    ("ê´‘ì‚°êµ¬", "ì²¨ë‹¨1ë™"): ["ì›”ê³„ë™", "ìŒì•”ë™", "ë¹„ì•„ë™"],
    ("ê´‘ì‚°êµ¬", "ì²¨ë‹¨2ë™"): ["ì›”ê³„ë™", "ì‚°ì›”ë™", "ìŒì•”ë™", "ìˆ˜ì™„ë™"],
    ("ê´‘ì‚°êµ¬", "ì‹ ê°€ë™"): ["ì‹ ê°€ë™", "ì‹ ì°½ë™"],
    ("ê´‘ì‚°êµ¬", "ìš´ë‚¨ë™"): ["ìš´ë‚¨ë™", "ì‹ ê°€ë™"],
    ("ê´‘ì‚°êµ¬", "ìˆ˜ì™„ë™"): ["ì‹ ê°€ë™", "ìˆ˜ì™„ë™", "ì¥ë•ë™", "í‘ì„ë™"],
    ("ê´‘ì‚°êµ¬", "í•˜ë‚¨ë™"): ["í•˜ë‚¨ë™", "ì§„ê³¡ë™", "ì˜¤ì„ ë™", "ì•ˆì²­ë™", "ì¥ìˆ˜ë™", "ì‚°ì •ë™", "ì¥ë•ë™", "í‘ì„ë™"],
    ("ê´‘ì‚°êµ¬", "ì„ê³¡ë™"): ["ì„ê³¡ë™", "ë™ì„ë™", "ì‚¼ë§‰ë™", "ê³ ë£¡ë™", "ì‹ ë£¡ë™", "ë‘ì •ë™", "ê´‘ì‚°ë™", "ì˜¤ì‚°ë™", "ì‚¬í˜¸ë™"],
    ("ê´‘ì‚°êµ¬", "ë™ê³¡ë™"): ["í•˜ì‚°ë™", "ìœ ê³„ë™", "ë³¸ë•ë™", "ìš©ë´‰ë™", "ìš”ê¸°ë™", "ë³µë£¡ë™", "ì†¡ëŒ€ë™"],
    ("ê´‘ì‚°êµ¬", "í‰ë™"): ["ì˜¥ë™", "ì›”ì „ë™", "ì¥ë¡ë™", "ì†¡ì´Œë™", "ì§€ì£½ë™", "ìš©ë™", "ìš©ê³¡ë™", "ì§€ì •ë™", "ëª…í™”ë™", "ë™ì‚°ë™", "ì—°ì‚°ë™"],
    ("ê´‘ì‚°êµ¬", "ì‚¼ë„ë™"): ["ë„ë•ë™", "ì†¡ì‚°ë™", "ì§€í‰ë™", "ì˜¤ìš´ë™", "ì‚¼ê±°ë™", "ì–‘ë™", "ë‚´ì‚°ë™", "ëŒ€ì‚°ë™", "ì†¡í•™ë™", "ì‹ ë™", "ì‚¼ë„ë™"],
    ("ê´‘ì‚°êµ¬", "ë³¸ëŸ‰ë™"): ["ë‚¨ì‚°ë™", "ì†¡ì¹˜ë™", "ì‚°ìˆ˜ë™", "ì„ ë™", "ì§€ì‚°ë™", "ì™•ë™", "ë¶ì‚°ë™", "ëª…ë„ë™", "ë™í˜¸ë™", "ë•ë¦¼ë™", "ì–‘ì‚°ë™", "ë™ë¦¼ë™"]
}

# ë²•ì •ë™+êµ¬ ì¡°í•©ìœ¼ë¡œ í–‰ì •ë™ ì°¾ê¸°
def find_administrative_dong(gu, legal_dong):
    if gu is None or legal_dong is None:
        return None
    for (mapping_gu, admin_dong), legal_dongs in ê´‘ì£¼_í–‰ì •ë™_ë²•ì •ë™_ë§¤í•‘.items():
        if gu == mapping_gu and legal_dong.replace('(ì¼ë¶€)', '') in [x.replace('(ì¼ë¶€)', '') for x in legal_dongs]:
            return admin_dong
    return None

# ------------------------- [1] ì›ë£¸ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° -------------------------

# êµ¬, ë²•ì •ë™ ì¶”ì¶œ
df['êµ¬'] = df['ë§¤ë¬¼ì£¼ì†Œ'].apply(extract_gu)
df['ë²•ì •ë™'] = df['ë§¤ë¬¼ì£¼ì†Œ'].apply(extract_dong)
df['í–‰ì •ë™'] = df.apply(lambda row: find_administrative_dong(row['êµ¬'], row['ë²•ì •ë™']), axis=1)

# ------------------------- [2] ì´ì¸êµ¬ìˆ˜, í‰ê· ì—°ë ¹ ì¶”ê°€ -------------------------
pop_age_df = pd.read_csv('ì§€ì—­êµ¬_ë™ë³„_ì´ì¸êµ¬ìˆ˜_í‰ê· ì—°ë ¹.csv', encoding='cp949')

# ì´ì¸êµ¬ìˆ˜ ì¶”ê°€
df = df.merge(pop_age_df[['ë™ì´ë¦„', 'ì´ì¸êµ¬ìˆ˜']], how='left', left_on='í–‰ì •ë™', right_on='ë™ì´ë¦„')
df = df.drop(columns=['ë™ì´ë¦„'])

# í‰ê· ì—°ë ¹ ì¶”ê°€
df = df.merge(pop_age_df[['ë™ì´ë¦„', 'í‰ê· ì—°ë ¹']], how='left', left_on='í–‰ì •ë™', right_on='ë™ì´ë¦„')
df = df.rename(columns={'í‰ê· ì—°ë ¹': 'ë™ë³„í‰ê· ì—°ë ¹'})
df = df.drop(columns=['ë™ì´ë¦„'])

print("âœ… ì´ì¸êµ¬ìˆ˜ì™€ í‰ê· ì—°ë ¹ ì¶”ê°€ ì™„ë£Œ!")

# ------------------------- [3] í‰ë‹¹ì „ì„¸ê°€ ì¶”ê°€ -------------------------
price_df = pd.read_csv('ê´‘ì£¼_ì˜¤í”¼ìŠ¤í…”_ì§€ì—­êµ¬_ë™ë³„_í‰ê· í‰ë‹¹ì „ì„¸ê°€.csv', encoding='utf-8-sig')

df = df.merge(
    price_df[['ì§€ì—­êµ¬', 'ë™ì´ë¦„', 'í‰ê· í‰ë‹¹ì „ì„¸ê°€(ë§Œì›)']],
    how='left',
    left_on=['êµ¬', 'í–‰ì •ë™'],
    right_on=['ì§€ì—­êµ¬', 'ë™ì´ë¦„']
)

df['í‰ê· í‰ë‹¹ì „ì„¸ê°€(ë§Œì›)'] = df['í‰ê· í‰ë‹¹ì „ì„¸ê°€(ë§Œì›)'].round()

# í•„ìš” ì—†ëŠ” ì»¬ëŸ¼ ì‚­ì œ
df = df.drop(columns=['ì§€ì—­êµ¬', 'ë™ì´ë¦„'])

print("âœ… í‰ë‹¹ì „ì„¸ê°€ ì¶”ê°€ ì™„ë£Œ!")

# ------------------------- [4] í‰ê· í‰ë‹¹ê°€ê²© ì¶”ê°€ -------------------------
price_land_df = pd.read_csv('ê´‘ì£¼_í† ì§€_ì§€ì—­êµ¬_ë™ë³„_í‰ê· í‰ë‹¹ì „ì„¸ê°€.csv', encoding='utf-8-sig')

# êµ¬, ë²•ì •ë™, í–‰ì •ë™ ì¶”ì¶œ
df['êµ¬'] = df['ë§¤ë¬¼ì£¼ì†Œ'].apply(extract_gu)
df['ë²•ì •ë™'] = df['ë§¤ë¬¼ì£¼ì†Œ'].apply(extract_dong)
df['í–‰ì •ë™'] = df.apply(lambda row: find_administrative_dong(row['êµ¬'], row['ë²•ì •ë™']), axis=1)

# í‰ê· í‰ë‹¹ê°€ê²© ì¶”ê°€
df = df.merge(price_land_df[['ì§€ì—­êµ¬', 'ë™ì´ë¦„', 'í‰ê· í‰ë‹¹ê°€ê²©(ë§Œì›)']],
                        how='left', left_on=['êµ¬', 'í–‰ì •ë™'], right_on=['ì§€ì—­êµ¬', 'ë™ì´ë¦„'])
df = df.drop(columns=['ì§€ì—­êµ¬', 'ë™ì´ë¦„'])
df['í‰ê· í‰ë‹¹ê°€ê²©(ë§Œì›)'] = df['í‰ê· í‰ë‹¹ê°€ê²©(ë§Œì›)'].round()

print("âœ… í† ì§€ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ!")

df = df[~df['í‰ê· í‰ë‹¹ê°€ê²©(ë§Œì›)'].isna() & (df['í‰ê· í‰ë‹¹ê°€ê²©(ë§Œì›)'].astype(str).str.strip() != '')]
df = df[~df['í‰ê· í‰ë‹¹ì „ì„¸ê°€(ë§Œì›)'].isna() & (df['í‰ê· í‰ë‹¹ì „ì„¸ê°€(ë§Œì›)'].astype(str).str.strip() != '')]
df = df[~df['ë™ë³„í‰ê· ì—°ë ¹'].isna() & (df['ë™ë³„í‰ê· ì—°ë ¹'].astype(str).str.strip() != '')]
df = df[~df['ì´ì¸êµ¬ìˆ˜'].isna() & (df['ì´ì¸êµ¬ìˆ˜'].astype(str).str.strip() != '')]

df.to_csv('ë‹¤ë°©_ì˜¤í”¼ìŠ¤í…”_DB_ì´ˆê¸°.csv', index=False)

# 'ì „ì„¸_ì—¬ë¶€' ì»¬ëŸ¼ì— X ê°’ì´ ìˆëŠ” í–‰ ì œê±°
df = df[df['ì „ì„¸_ì—¬ë¶€'].isna() | (df['ì „ì„¸_ì—¬ë¶€'].astype(str).str.strip() == 'O')]

# ì „ì„¸ë§Œ ì €ì¥
df.to_csv('ë‹¤ë°©_ì˜¤í”¼ìŠ¤í…”_DB_ë„£ê¸°íŒŒì¼.csv', index=False)

# ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ í˜ì´ì§€ì— ì‚¬ìš©í•  íŒŒì¼ ì €ì¥ ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡



# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
file_path = 'ë‹¤ë°©_ì˜¤í”¼ìŠ¤í…”_DB_ì´ˆê¸°.csv'
df = pd.read_csv(file_path)

# ìˆ«ì ì¶”ì¶œ í•¨ìˆ˜
def extract_fee(text):
    if pd.isna(text):
        return 0
    text = str(text).strip()
    if 'í™•ì¸ë¶ˆê°€' in text or 'ì—†ìŒ' in text:
        return 0
    match = re.search(r'\d+', text)
    return int(match.group()) if match else 0

# ì ìš©
df['ê´€ë¦¬ë¹„'] = df['ê´€ë¦¬ë¹„'].apply(extract_fee)

# 2ì°¨ ë³€í™˜: 5000ì´ë©´ ê·¸ëŒ€ë¡œ, ê·¸ ì™¸ëŠ” x 10000
df['ê´€ë¦¬ë¹„'] = df['ê´€ë¦¬ë¹„'].apply(lambda x: x if x == 5000 else x * 10000)

# 'ì£¼ì°¨ê°€ëŠ¥ì—¬ë¶€' ì»¬ëŸ¼ ê°’ ì¹˜í™˜
df['ì£¼ì°¨ê°€ëŠ¥ì—¬ë¶€'] = df['ì£¼ì°¨ê°€ëŠ¥ì—¬ë¶€'].map({'ê°€ëŠ¥': 1, 'ë¶ˆê°€ëŠ¥': 0})

# 'ì£¼ì°¨ê°€ëŠ¥ì—¬ë¶€' ì»¬ëŸ¼ ê°’ ì¹˜í™˜
df['ì—˜ë¦¬ë² ì´í„°'] = df['ì—˜ë¦¬ë² ì´í„°'].map({'ìˆìŒ': 1, 'ì—†ìŒ': 0})

# ê±´ë¬¼ì¸µ ë¬¸ìì—´ â†’ ìˆ«ìí˜• ì¸µìˆ˜ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def extract_floor(text):
    if pd.isna(text):
        return None
    text = str(text)
    if 'ì§€í•˜' in text:
        match = re.search(r'\d+', text)
        return -int(match.group()) if match else None
    match = re.search(r'\d+', text)
    return int(match.group()) if match else None

# ìˆ«ìì¸µìˆ˜ ì»¬ëŸ¼ ìƒì„±
df['ê±´ë¬¼ì¸µìˆ˜'] = df['ê±´ë¬¼ì¸µ'].apply(extract_floor)

# ì¡°ê±´: ê±´ë¬¼ì¸µìˆ˜ >= 6ì¸ í–‰ì€ ì—˜ë¦¬ë² ì´í„°ë¥¼ ë¬´ì¡°ê±´ 1ë¡œ ë°”ê¿ˆ
df.loc[df['ê±´ë¬¼ì¸µìˆ˜'] >= 6, 'ì—˜ë¦¬ë² ì´í„°'] = 1

# ê±´ë¬¼ì¸µê³¼ í•´ë‹¹ì¸µ â†’ ìˆ«ìë¡œ ë³€í™˜
def floor_to_number(text):
    if pd.isna(text):
        return None
    text = str(text).strip()
    
    if 'ì§€í•˜' in text or 'ë°˜ì§€í•˜' in text:
        return 0
    if 'ì˜¥íƒ‘' in text:
        return 0
    
    match = re.search(r'\d+', text)
    if match:
        return int(match.group())
    
    # ìƒëŒ€ì  ì¸µ í‘œí˜„ì€ ì—¬ê¸°ì„  None
    return None

df['ê±´ë¬¼ì¸µìˆ˜'] = df['ê±´ë¬¼ì¸µ'].apply(floor_to_number)
df['í•´ë‹¹ì¸µìˆ˜'] = df['í•´ë‹¹ì¸µ'].apply(floor_to_number)

# ì¸µë“±ê¸‰ ê²°ì • í•¨ìˆ˜
def assign_floor_grade(row):
    ì¸µí‘œí˜„ = str(row['í•´ë‹¹ì¸µ']) if pd.notna(row['í•´ë‹¹ì¸µ']) else ''
    
    if any(x in ì¸µí‘œí˜„ for x in ['ê³ ì¸µ']):
        return 3
    elif any(x in ì¸µí‘œí˜„ for x in ['ì¤‘ì¸µ']):
        return 2
    elif any(x in ì¸µí‘œí˜„ for x in ['ì €ì¸µ', 'ë°˜ì§€í•˜', 'ì˜¥íƒ‘']):
        return 1
    elif row['í•´ë‹¹ì¸µìˆ˜'] is not None and row['ê±´ë¬¼ì¸µìˆ˜'] not in [0, None, '']:

        # ë¹„ìœ¨ ê³„ì‚°
        try:
            ratio = row['í•´ë‹¹ì¸µìˆ˜'] / row['ê±´ë¬¼ì¸µìˆ˜']
            if ratio <= 1/3:
                return 1
            elif ratio <= 2/3:
                return 2
            else:
                return 3
        except:
            return None
    else:
        return None

# ì¸µë“±ê¸‰ ì ìš©
df['ì¸µë“±ê¸‰'] = df.apply(assign_floor_grade, axis=1)

# ì‚­ì œí•  ì»¬ëŸ¼ ëª©ë¡
columns_to_drop = ['í•´ë‹¹ì¸µ', 'ê±´ë¬¼ì¸µ', 'í•´ë‹¹ì¸µìˆ˜', 'ê±´ë¬¼ì¸µìˆ˜']

# ì»¬ëŸ¼ ì‚­ì œ
df.drop(columns=columns_to_drop, inplace=True)

# ìˆ«ì ì¶”ì¶œ í•¨ìˆ˜
def extract_number(text):
    if pd.isna(text):
        return None
    match = re.search(r'\d+', str(text))
    return int(match.group()) if match else None
# ì ìš©
df['ë°© ìˆ˜'] = df['ë°© ìˆ˜'].apply(extract_number)
df['ìš•ì‹¤ ìˆ˜'] = df['ìš•ì‹¤ ìˆ˜'].apply(extract_number)

# ë³€í™˜ ëŒ€ìƒ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
columns_to_convert = ['ì›”ì„¸ë³´ì¦ê¸ˆ', 'ì›”ì„¸ê°€ê²©']

# ê° ì»¬ëŸ¼ì— ëŒ€í•´ ë³€í™˜ ì ìš©
for col in columns_to_convert:
    df[col] = pd.to_numeric(df[col], errors='coerce')  # ìˆ«ìë¡œ ë³€í™˜
    df[col] = df[col].apply(lambda x: x * 10000 if pd.notna(x) else x)  # ë§Œì› ë‹¨ìœ„ ë³€í™˜

# ì „ì„¸ ê¸ˆì•¡ ì²˜ë¦¬ í•¨ìˆ˜
def convert_jeonse(value):
    if pd.isna(value):
        return None
    value = str(value).strip().replace(',', '')

    # 'ì–µ' ë‹¨ìœ„ê°€ í¬í•¨ëœ ê²½ìš°
    if 'ì–µ' in value:
        match = re.match(r'(\d+)ì–µ(\d+)?', value)
        if match:
            ì–µ = int(match.group(1)) * 10000
            ì²œ = int(match.group(2)) if match.group(2) else 0
            return ì–µ + ì²œ
        else:
            return None
    else:
        # ê·¸ëƒ¥ ìˆ«ìì¼ ê²½ìš°
        match = re.search(r'\d+', value)
        return int(match.group()) if match else None

# ì „ì„¸ ìˆ«ìí™” â†’ ì› ë‹¨ìœ„ë¡œ ë³€í™˜
df['ì „ì„¸'] = df['ì „ì„¸'].apply(convert_jeonse)
df['ì „ì„¸'] = df['ì „ì„¸'].apply(lambda x: x * 10000 if pd.notna(x) else x)

# ì „ì›”ì„¸ ì „í™˜ìœ¨
conversion_rate = 0.07

# ì „ì„¸ ì¶”ì •ê°€ ê³„ì‚° í•¨ìˆ˜
def estimate_jeonse(row):
    if not pd.isna(row['ì „ì„¸']):
        return row['ì „ì„¸']
    elif pd.notna(row['ì›”ì„¸ë³´ì¦ê¸ˆ']) and pd.notna(row['ì›”ì„¸ê°€ê²©']):
        return row['ì›”ì„¸ë³´ì¦ê¸ˆ'] + (row['ì›”ì„¸ê°€ê²©'] * 12 / conversion_rate)
    else:
        return None

# ê³„ì‚° ì ìš©
df['ì „ì„¸ì¶”ì •ê°€'] = df.apply(estimate_jeonse, axis=1)

# ğŸ” ë°±ë§Œ ì› ë‹¨ìœ„ ë°˜ì˜¬ë¦¼
df['ì „ì„¸ì¶”ì •ê°€'] = df['ì „ì„¸ì¶”ì •ê°€'].apply(lambda x: round(x, -6) if pd.notna(x) else None)

# ì‚­ì œí•  ì»¬ëŸ¼ ëª©ë¡
columns_to_drop = ['ì›”ì„¸ë³´ì¦ê¸ˆ', 'ì›”ì„¸ê°€ê²©', 'ì „ì„¸']

# ì»¬ëŸ¼ ì‚­ì œ
df.drop(columns=columns_to_drop, inplace=True)

# 'ã¡' ë° ê³µë°± ì œê±° â†’ ìˆ«ì(float) ë³€í™˜
df['ì „ìš©ë©´ì '] = df['ì „ìš©ë©´ì '].astype(str).str.replace(r'[^\d\.]', '', regex=True).astype(float)

# í‰ìˆ˜ ê³„ì‚° (ì •ìˆ˜ë¡œ ë³€í™˜)
df['ì „ìš©ë©´ì _í‰'] = (df['ì „ìš©ë©´ì '] * 0.3025).astype(int)

# ì‚­ì œí•  ì»¬ëŸ¼ ëª©ë¡
columns_to_drop = ['ì „ìš©ë©´ì ']

# ì»¬ëŸ¼ ì‚­ì œ
df.drop(columns=columns_to_drop, inplace=True)

# ë°©í–¥ë³„ ì ìˆ˜ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬
direction_score = {
    'ë‚¨': 5,
    'ë‚¨ë™': 4.5,
    'ë‚¨ì„œ': 4,
    'ë™': 3.5,
    'ì„œ': 3,
    'ë¶ë™': 2.5,
    'ë¶ì„œ': 2,
    'ë¶': 1
}

# ë°©í–¥ì ìˆ˜ ê³„ì‚° (ì—†ê±°ë‚˜ ì´ìƒê°’ì€ 0ìœ¼ë¡œ ì²˜ë¦¬)
df['ë°©í–¥ì ìˆ˜'] = df['ë°©í–¥'].map(direction_score).fillna(0)

# 'ì…ì£¼ê°€ëŠ¥' ì»¬ëŸ¼ì— 'ì¦‰ì‹œ ì…ì£¼'ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ 1, ì•„ë‹ˆë©´ 0
df['ì¦‰ì‹œì…ì£¼ì—¬ë¶€'] = df['ì…ì£¼ê°€ëŠ¥ì¼'].apply(lambda x: 1 if pd.notna(x) and 'ì¦‰ì‹œ ì…ì£¼' in str(x) else 0)

# ê°’ì´ ìˆìœ¼ë©´ 1, ì—†ìœ¼ë©´ 0
df['ë‹¨ê¸°ì„ëŒ€ì—¬ë¶€'] = df['ë‹¨ê¸°ì„ëŒ€'].apply(lambda x: 1 if pd.notna(x) and str(x).strip() != '' else 0)

# ì‚­ì œí•  ì»¬ëŸ¼ ëª©ë¡
columns_to_drop = ['ë‹¨ê¸°ì„ëŒ€', 'ì…ì£¼ê°€ëŠ¥ì¼', 'ë°©í–¥']

# ì»¬ëŸ¼ ì‚­ì œ
df.drop(columns=columns_to_drop, inplace=True)

# ì ìˆ˜ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬
score_map = {
    'ê³µë™ì£¼íƒ': 1.0,
    'ë‹¨ë…ì£¼íƒ': 0.3,
    'ì—…ë¬´ì‹œì„¤': 0.1,
    'ìˆ™ë°•ì‹œì„¤': 0.0,
    'ì œ1ì¢…ê·¼ë¦°ìƒí™œì‹œì„¤': 0.0,
    'ì œ2ì¢…ê·¼ë¦°ìƒí™œì‹œì„¤': 0.0,
    'êµìœ¡ì—°êµ¬ì‹œì„¤': 0.0,
    'ê³µì¥': 0.0,
    'ë¯¸ë“±ê¸°ê±´ë¬¼': 0.0,
    'ê¸°íƒ€(ì •ì°©ë¬¼ ë“±)': 0.0,
    'ê·¸ ë°–ì— í† ì§€ì˜ ì •ì°©ë¬¼': 0.0
}

# ì „ì²˜ë¦¬: ë¬¸ìì—´ë¡œ ë³€í™˜ + strip ì²˜ë¦¬
df['ê±´ì¶•ë¬¼ìš©ë„'] = df['ê±´ì¶•ë¬¼ìš©ë„'].astype(str).str.strip()

# 'ì—†ìŒ', 'nan', '', ë“± ì²˜ë¦¬ í¬í•¨
df['ë³´ì¦ë³´í—˜ì ìˆ˜'] = df['ê±´ì¶•ë¬¼ìš©ë„'].apply(lambda x: score_map.get(x, 0.0) if x.lower() not in ['nan', 'ì—†ìŒ', ''] else 0.0)

# ì‚­ì œí•  ì»¬ëŸ¼ ëª©ë¡
columns_to_drop = ['ê±´ì¶•ë¬¼ìš©ë„']

# ì»¬ëŸ¼ ì‚­ì œ
df.drop(columns=columns_to_drop, inplace=True)

# ê¸°ì¤€ ë‚ ì§œ: 2025ë…„ 4ì›” 11ì¼
today = datetime(2025, 4, 11)

# ì‚¬ìš©ìŠ¹ì¸ì¼ â†’ ì—°ì°¨ ê³„ì‚° í•¨ìˆ˜
def get_building_age(approval_date):
    try:
        date = pd.to_datetime(approval_date, errors='coerce')
        if pd.isna(date):
            return None
        # ì—°ì°¨ì— ë”°ë¼ ì ìˆ˜ ë¶€ì—¬ í•¨ìˆ˜
        year_diff = today.year - date.year
        if (today.month, today.day) < (date.month, date.day):
            year_diff -= 1
        return year_diff
    except:
        return None

# ì—°ì°¨ì— ë”°ë¼ ì ìˆ˜ ë¶€ì—¬ í•¨ìˆ˜
def get_building_score(years):
    if years is None:
        return 0.0
    elif years <= 5:
        return 1.0  # ì‹ ì¶•
    elif years <= 15:
        return 0.5  # ì¤€ì‹ ì¶•
    else:
        return 0.0  # êµ¬ì¶•

# ì ìš©
df['ê±´ì¶•ì—°ì°¨'] = df['ì‚¬ìš©ìŠ¹ì¸ì¼'].apply(get_building_age)
df['ê±´ì¶•ì ìˆ˜'] = df['ê±´ì¶•ì—°ì°¨'].apply(get_building_score)

# ì‚­ì œí•  ì»¬ëŸ¼ ëª©ë¡
columns_to_drop = ['ì‚¬ìš©ìŠ¹ì¸ì¼']

# ì»¬ëŸ¼ ì‚­ì œ
df.drop(columns=columns_to_drop, inplace=True)

# ì˜µì…˜ ì ìˆ˜ ë§¤í•‘
option_scores = {
    'ëƒ‰ì¥ê³ ': 1.0,
    'ì„¸íƒê¸°': 1.0,
    'ê°€ìŠ¤ë ˆì¸ì§€': 1.0,
    'ì „ìë ˆì¸ì§€': 1.0,
    'ì¹¨ëŒ€': 0.8,
    'ì˜·ì¥': 0.6,
    'ì±…ìƒ': 0.4,
    'ì‡¼íŒŒ': 0.3,
    'ì‹íƒ': 0.5,
    'ì‹±í¬ëŒ€': 1.0,
    'ì¸ë•ì…˜': 0.4,
    'ê°€ìŠ¤ì˜¤ë¸': 0.3,
    'ê±´ì¡°ê¸°': 0.8,
    'ìŠ¤íƒ ë“œí˜•': 0.5,
    'ë²½ê±¸ì´í˜•': 0.6,
    'ë§ˆë‹¹': 0.3,
    'ë¬´ì¸íƒë°°í•¨': 0.3,
    'ë¹„ë°': 0.5,
    'ìƒ¤ì›Œë¶€ìŠ¤': 0.5,
    'ìš•ì¡°': 0.4,
    'ë¶ˆë°•ì´ì¥': 0.5,
    'ì‹ ë°œì¥': 0.6,
    'ì²œì¥í˜•': 0.4,
    'í™”ì¬ê²½ë³´ê¸°': 0.2,
    'ë² ë€ë‹¤': 0.4,
    'ì‹ê¸°ì„¸ì²™ê¸°': 0.3,
    'TV': 0.3
}

# ì˜µì…˜ ì ìˆ˜ ê³„ì‚° í•¨ìˆ˜
def calculate_option_score(option_text):
    if pd.isna(option_text):
        return 0.0
    score = 0.0
    for keyword, point in option_scores.items():
        if keyword in option_text:
            score += point
    return round(score, 1)  # â† ì†Œìˆ˜ì  1ìë¦¬ ë°˜ì˜¬ë¦¼

# ì ìš©
df['ì˜µì…˜ì ìˆ˜'] = df['ì˜µì…˜ì •ë³´'].apply(calculate_option_score)

# ì‚­ì œí•  ì»¬ëŸ¼ ëª©ë¡
columns_to_drop = ['ì˜µì…˜ì •ë³´']

# ì»¬ëŸ¼ ì‚­ì œ
df.drop(columns=columns_to_drop, inplace=True)

# ì»¬ëŸ¼ëª… ë³€ê²½
df.rename(columns={'ì „ì„¸ì¶”ì •ê°€': 'ì „ì„¸'}, inplace=True)

# ì €ì¥
df.to_csv('ë‹¤ë°©_ê´‘ì£¼_ì˜¤í”¼ìŠ¤í…”_ìˆ˜ì¹˜í™”.csv', index=False)


# 4. MLOps

# âœ… 4-1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv('ë‹¤ë°©_ê´‘ì£¼_ì˜¤í”¼ìŠ¤í…”_ìˆ˜ì¹˜í™”.csv')
df = df.dropna()

# âœ… 4-2. ë¡œê·¸ ë³€í™˜
df['log_ì „ì„¸'] = np.log1p(df['ì „ì„¸'])
df['log_ê±´ì¶•ì—°ì°¨'] = np.log1p(df['ê±´ì¶•ì—°ì°¨'])
df['log_ì „ìš©ë©´ì '] = np.log1p(df['ì „ìš©ë©´ì _í‰'])

# âœ… 4-3. í”¼ì²˜ ì •ì˜
features = [
    'ë°© ìˆ˜', 'ìš•ì‹¤ ìˆ˜', 'ì—˜ë¦¬ë² ì´í„°', 'ì¸µë“±ê¸‰',
    'ê±´ì¶•ì ìˆ˜', 'ë³´ì¦ë³´í—˜ì ìˆ˜', 'ì¦‰ì‹œì…ì£¼ì—¬ë¶€', 'ë‹¨ê¸°ì„ëŒ€ì—¬ë¶€', 'ë°©í–¥ì ìˆ˜',
    'log_ê±´ì¶•ì—°ì°¨', 'log_ì „ìš©ë©´ì ', 'ì´ì¸êµ¬ìˆ˜', 'ë™ë³„í‰ê· ì—°ë ¹', 'í‰ê· í‰ë‹¹ì „ì„¸ê°€(ë§Œì›)', 'í‰ê· í‰ë‹¹ê°€ê²©(ë§Œì›)'
]

X = df[features].reset_index(drop=True)
y_log = df['log_ì „ì„¸'].reset_index(drop=True)

# âœ… 4-4. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í•  (8:2)
X_train, X_test, y_train_log, y_test_log = train_test_split(X, y_log, test_size=0.2, random_state=42)

# âœ… 4-5. ìŠ¤ì¼€ì¼ë§
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# âœ… 4-6. ëª¨ë¸ ì •ì˜
models = {
    'LightGBM': LGBMRegressor(random_state=42),
    'XGBoost': XGBRegressor(random_state=42),
    'CatBoost': CatBoostRegressor(verbose=0, random_state=42),
    'Stacking(LGBM+XGB+Cat)': StackingRegressor(
        estimators=[
            ('lgbm', LGBMRegressor(random_state=42)),
            ('xgb', XGBRegressor(random_state=42)),
            ('cat', CatBoostRegressor(verbose=0, random_state=42))
        ],
        final_estimator=LinearRegression(),
        cv=5
    )
}

# âœ… 4-7. ì—¬ëŸ¬ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
results = {}

for name, model in models.items():
    model.fit(X_train_scaled, y_train_log)
    log_pred = model.predict(X_test_scaled)
    pred = np.expm1(log_pred)
    y_real = np.expm1(y_test_log)

    mae = mean_absolute_error(y_real, pred)
    mape = mean_absolute_percentage_error(y_real, pred)
    r2 = r2_score(y_real, pred)

    results[name] = (model, mae, mape, r2)

# âœ… 4-8. ê°€ì¥ ì¢‹ì€ ëª¨ë¸ ì„ íƒ (MAPE ìš°ì„ , MAE tie-breaker)
best_name, (best_model, best_mae, best_mape, best_r2) = sorted(
    results.items(),
    key=lambda item: (item[1][2], item[1][1])
)[0]

# âœ… 4-9. ê²°ê³¼ ì¶œë ¥
print("\nğŸ“Š ì˜¤ëŠ˜ ì „ì²´ ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½:")
results_df = pd.DataFrame(
    {name: {'MAE': mae, 'MAPE': mape, 'R2': r2} for name, (_, mae, mape, r2) in results.items()}
).T
results_df['MAE'] = results_df['MAE'].apply(lambda x: f"{x:,.0f} ì›")
results_df['MAPE'] = results_df['MAPE'].apply(lambda x: f"{x*100:.2f} %")
results_df['R2'] = results_df['R2'].apply(lambda x: f"{x:.4f}")
print(results_df)

print(f"\nğŸŒŸ ì˜¤ëŠ˜ ê°€ì¥ ì¢‹ì€ ëª¨ë¸ì€: {best_name}")
print(f" - MAE: {best_mae:.2f}ì›")
print(f" - MAPE: {best_mape*100:.2f}%")
print(f" - RÂ²: {best_r2:.4f}")

# âœ… 4-10. ìµœì‹  ëª¨ë¸ ì €ì¥
joblib.dump(best_model, "of_model_latest.pkl")
print("ğŸ’¾ of_model_latest.pkl ì €ì¥ ì™„ë£Œ!")

# âœ… 4-11. ê¸°ì¡´ ëª¨ë¸ê³¼ ë¹„êµ
if os.path.exists("of_model_best.pkl"):
    prev_best_model = joblib.load("of_model_best.pkl")
    log_pred_prev = prev_best_model.predict(X_test_scaled)
    pred_prev = np.expm1(log_pred_prev)

    prev_mae = mean_absolute_error(y_real, pred_prev)
    prev_mape = mean_absolute_percentage_error(y_real, pred_prev)

    print(f"\nğŸ† ê¸°ì¡´ best ëª¨ë¸ í‰ê°€ ê²°ê³¼:")
    print(f" - MAE: {prev_mae:.2f}ì›")
    print(f" - MAPE: {prev_mape*100:.2f}%")
else:
    print("\nâš ï¸ ê¸°ì¡´ of_model_best.pklì´ ì—†ìŠµë‹ˆë‹¤. ìµœì´ˆ ì €ì¥ ì§„í–‰.")
    prev_mape = float('inf')
    prev_mae = float('inf')

# âœ… 4-12. ì„±ëŠ¥ ë¹„êµí•˜ì—¬ ê°±ì‹  ì—¬ë¶€ íŒë‹¨
if (best_mape < prev_mape) or (best_mape == prev_mape and best_mae < prev_mae):
    joblib.dump(best_model, "of_model_best.pkl")
    print("\nâœ… ìƒˆë¡œìš´ ëª¨ë¸ì´ ë” ì¢‹ì•„ì„œ best ëª¨ë¸ë¡œ ê°±ì‹ ë˜ì—ˆìŠµë‹ˆë‹¤.")
else:
    print("\nâŒ ê¸°ì¡´ best ëª¨ë¸ì´ ë” ìš°ìˆ˜í•˜ì—¬ ê°±ì‹ í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


#### 5. ì˜ˆì¸¡ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°

# 5-1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv("ë‹¤ë°©_ê´‘ì£¼_ì˜¤í”¼ìŠ¤í…”_ìˆ˜ì¹˜í™”.csv")
df = df.dropna()

# 5-2. ë¡œê·¸ ì „ìš©ë©´ì , ê±´ì¶•ì—°ì°¨ ì¶”ê°€ (ëª¨ë¸ í•™ìŠµ ë•Œ ì‚¬ìš©í•œ íŒŒìƒë³€ìˆ˜)
df['log_ì „ì„¸'] = np.log1p(df['ì „ì„¸'])
df['log_ê±´ì¶•ì—°ì°¨'] = np.log1p(df['ê±´ì¶•ì—°ì°¨'])
df['log_ì „ìš©ë©´ì '] = np.log1p(df['ì „ìš©ë©´ì _í‰'])

# 5-3. í”¼ì²˜ ì •ì˜ (í•™ìŠµ ì‹œ ì‚¬ìš©í•œ ìˆœì„œì™€ ë™ì¼í•˜ê²Œ)
features = [
    'ë°© ìˆ˜', 'ìš•ì‹¤ ìˆ˜', 'ì—˜ë¦¬ë² ì´í„°', 'ì¸µë“±ê¸‰',
    'ê±´ì¶•ì ìˆ˜', 'ë³´ì¦ë³´í—˜ì ìˆ˜', 'ì¦‰ì‹œì…ì£¼ì—¬ë¶€', 'ë‹¨ê¸°ì„ëŒ€ì—¬ë¶€', 'ë°©í–¥ì ìˆ˜',
    'log_ê±´ì¶•ì—°ì°¨', 'log_ì „ìš©ë©´ì ', 'ì´ì¸êµ¬ìˆ˜', 'ë™ë³„í‰ê· ì—°ë ¹', 'í‰ê· í‰ë‹¹ì „ì„¸ê°€(ë§Œì›)', 'í‰ê· í‰ë‹¹ê°€ê²©(ë§Œì›)'
]

X = df[features].reset_index(drop=True)

# 5-4. ìŠ¤ì¼€ì¼ë§
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 5-5. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (latest ë˜ëŠ” best)
model = joblib.load("of_model_best.pkl")  # ë˜ëŠ” "model_latest.pkl"

# 5-6. ì˜ˆì¸¡ ë° ì—­ë³€í™˜
log_pred = model.predict(X_scaled)
pred = np.expm1(log_pred)
y_real = np.expm1(y_log)

# 5-7 ê²°ê³¼ ì •ë¦¬
df_selected = df.copy().reset_index(drop=True)
df_selected["ì‹¤ì œ ì „ì„¸ê°€"] = (y_real / 10000).round(1)
df_selected["ì˜ˆì¸¡ ì „ì„¸ê°€"] = (pred / 10000).round(1)
df_selected["ì˜¤ì°¨(ë§Œì›)"] = (df_selected["ì˜ˆì¸¡ ì „ì„¸ê°€"] - df_selected["ì‹¤ì œ ì „ì„¸ê°€"]).round(1)
df_selected["ì˜¤ì°¨ìœ¨(%)"] = ((df_selected["ì˜¤ì°¨(ë§Œì›)"].abs() / df_selected["ì‹¤ì œ ì „ì„¸ê°€"]) * 100).round(2)

# 5-8 ì‚¬ê¸°ìœ„í—˜ë„ ë¶„ë¥˜ í•¨ìˆ˜
def classify_risk(error):
    if error < 10:
        return "ğŸŸ¢ ì•ˆì „"
    elif error < 25:
        return "ğŸŸ¡ ì£¼ì˜"
    else:
        return "ğŸ”´ ìœ„í—˜"

df_selected["ì‚¬ê¸°ìœ„í—˜ë„"] = df_selected["ì˜¤ì°¨ìœ¨(%)"].apply(classify_risk)

# 5-9 ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±°
df_selected.drop(columns=["log_ì „ì„¸", "log_ê±´ì¶•ì—°ì°¨", "log_ì „ìš©ë©´ì "], inplace=True)

# ì €ì¥
df_selected.to_csv("ì „ì„¸ì˜ˆì¸¡_ì˜¤í”¼ìŠ¤í…”_ì •ë¦¬ë³¸.csv", index=False)
print("ğŸ“ ì €ì¥ ì™„ë£Œ: ì „ì„¸ì˜ˆì¸¡_ì˜¤í”¼ìŠ¤í…”_ì •ë¦¬ë³¸.csv")


# 6. í˜ì´ì§€ í‘œì‹œë¥¼ ìœ„í•œ ë°ì´í„° ì²˜ë¦¬

# ğŸ”¸ ì›ë³¸ ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv("ì „ì„¸ì˜ˆì¸¡_ì˜¤í”¼ìŠ¤í…”_ì •ë¦¬ë³¸.csv")

# ğŸ”¸ ê°€ê²© í¬ë§· í•¨ìˆ˜
def format_price(val):
    val = int(val)
    if val >= 10000:
        man = val % 10000
        return f"1ì–µ{man}" if man != 0 else "1ì–µ"
    else:
        return str(val)

# ğŸ”¸ ì˜ˆì¸¡ ì „ì„¸ê°€ëŠ” 100ë‹¨ìœ„ ë°˜ì˜¬ë¦¼ í›„ í¬ë§·
def format_predicted(val):
    val = int(round(val, -2))
    if val >= 10000:
        man = val % 10000
        return f"1ì–µ{man}" if man != 0 else "1ì–µ"
    else:
        return str(val)

# ğŸ”¸ ë‹¤ì‹œ ìˆ«ìë¡œ íŒŒì‹±í•˜ëŠ” í•¨ìˆ˜
def parse_price_string(s):
    if "ì–µ" in s:
        s = s.replace("ì–µ", "")
        return 10000 + int(s) if s else 10000
    else:
        return int(s)

# ğŸ”¸ ì‹¤ì œ ìˆ«ì ì—´ ì¶”ì¶œ
real_values = df["ì‹¤ì œ ì „ì„¸ê°€"].astype(float)
pred_values = df["ì˜ˆì¸¡ ì „ì„¸ê°€"].astype(float)

# ğŸ”¸ ì˜¤ì°¨ ë° ì˜¤ì°¨ìœ¨ ê³„ì‚°
df["ì˜¤ì°¨(ë§Œì›)"] = (pred_values - real_values).astype(int)
df["ì˜¤ì°¨ìœ¨(%)"] = ((df["ì˜¤ì°¨(ë§Œì›)"].abs() / real_values) * 100).round(2)

# ğŸ”¸ ë‹¤ì‹œ ë³´ê¸° ì¢‹ê²Œ í¬ë§·
df["ì‹¤ì œ ì „ì„¸ê°€"] = real_values.apply(format_price)
df["ì˜ˆì¸¡ ì „ì„¸ê°€"] = pred_values.round(-2).apply(format_predicted)

# ğŸ”¸ ì €ì¥
df.to_csv("ì „ì„¸ì˜ˆì¸¡_ì˜¤í”¼ìŠ¤í…”_í‘œì‹œì™„ë£Œ.csv", index=False)
print("ğŸ“ ì €ì¥ ì™„ë£Œ: ì „ì„¸ì˜ˆì¸¡_ì˜¤í”¼ìŠ¤í…”_í‘œì‹œì™„ë£Œ.csv")

# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
file_path = 'ì „ì„¸ì˜ˆì¸¡_ì˜¤í”¼ìŠ¤í…”_í‘œì‹œì™„ë£Œ.csv'
df = pd.read_csv(file_path)

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv('ì „ì„¸ì˜ˆì¸¡_ì˜¤í”¼ìŠ¤í…”_í‘œì‹œì™„ë£Œ.csv').dropna()

# íŒŒìƒë³€ìˆ˜ ì¶”ê°€
df['log_ê±´ì¶•ì—°ì°¨'] = np.log1p(df['ê±´ì¶•ì—°ì°¨'])
df['log_ì „ìš©ë©´ì '] = np.log1p(df['ì „ìš©ë©´ì _í‰'])

# ì „ì²´ ëª¨ë¸ í•™ìŠµ í”¼ì²˜ (15ê°œ)
full_features = [
    'ë°© ìˆ˜', 'ìš•ì‹¤ ìˆ˜', 'ì—˜ë¦¬ë² ì´í„°', 'ì¸µë“±ê¸‰',
    'ê±´ì¶•ì ìˆ˜', 'ë³´ì¦ë³´í—˜ì ìˆ˜', 'ì¦‰ì‹œì…ì£¼ì—¬ë¶€', 'ë‹¨ê¸°ì„ëŒ€ì—¬ë¶€', 'ë°©í–¥ì ìˆ˜',
    'log_ê±´ì¶•ì—°ì°¨', 'log_ì „ìš©ë©´ì ', 'ì´ì¸êµ¬ìˆ˜', 'ë™ë³„í‰ê· ì—°ë ¹', 'í‰ê· í‰ë‹¹ì „ì„¸ê°€(ë§Œì›)', 'í‰ê· í‰ë‹¹ê°€ê²©(ë§Œì›)'
]

# SHAP ê¸°ì—¬ë„ë¥¼ ë³´ê³  ì‹¶ì€ ì£¼ìš” í”¼ì²˜ (7ê°œ)
target_features = [    
    'log_ê±´ì¶•ì—°ì°¨',  
    'log_ì „ìš©ë©´ì ',         
    'í‰ê· í‰ë‹¹ê°€ê²©(ë§Œì›)',        
    'í‰ê· í‰ë‹¹ì „ì„¸ê°€(ë§Œì›)',           
    'ì´ì¸êµ¬ìˆ˜',           
    'ë™ë³„í‰ê· ì—°ë ¹',              
    'ë°©í–¥ì ìˆ˜'         
]

# ìƒˆë¡œ ì¶”ê°€í•  ì»¬ëŸ¼ëª… ì§€ì •
new_columns = [
    'log_ê±´ì¶•ì—°ì°¨ ì ìˆ˜',
    'log_ì „ìš©ë©´ì  ì ìˆ˜',
    'í‰ê· í‰ë‹¹ê°€ê²©(ë§Œì›) ì ìˆ˜',
    'í‰ê· í‰ë‹¹ì „ì„¸ê°€(ë§Œì›) ì ìˆ˜',
    'ì´ì¸êµ¬ìˆ˜ ì ìˆ˜',
    'ë™ë³„í‰ê· ì—°ë ¹ ì ìˆ˜',
    'ë°©í–¥ ì ìˆ˜'
]

# ì…ë ¥ ê°’ ì¤€ë¹„ ë° ìŠ¤ì¼€ì¼ë§
X = df[full_features].reset_index(drop=True)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ë° ì¶”ì¶œ
model = joblib.load("of_model_best.pkl")

# SHAP ê¸°ì—¬ë„ ê³„ì‚°
if isinstance(model, LGBMRegressor):
    shap_values = model.predict(X, pred_contrib=True)
    contrib_df = pd.DataFrame(shap_values[:, :-1], columns=full_features)

elif isinstance(model, XGBRegressor):
    explainer = shap.Explainer(model, X_scaled)
    shap_values = explainer(X_scaled)
    contrib_df = pd.DataFrame(shap_values.values, columns=full_features)

elif isinstance(model, CatBoostRegressor):
    explainer = shap.Explainer(model, X_scaled)
    shap_values = explainer(X_scaled)
    contrib_df = pd.DataFrame(shap_values.values, columns=full_features)

elif isinstance(model, StackingRegressor):
    explainer = shap.KernelExplainer(model.predict, shap.sample(X_scaled, 100))
    shap_values = explainer.shap_values(X_scaled)
    contrib_df = pd.DataFrame(shap_values, columns=full_features)

else:
    raise ValueError("âŒ ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤. SHAP ê³„ì‚° ë¶ˆê°€.")
# í•„ìš”í•œ í”¼ì²˜ë§Œ ì„ íƒ í›„ ìƒˆ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë³€ê²½
contrib_selected = contrib_df[target_features]
contrib_selected.columns = new_columns

# SHAP ì ìˆ˜ 0~100 ì •ê·œí™”
contrib_normalized = contrib_selected.apply(lambda x: 100 * (x - x.min()) / (x.max() - x.min()))
contrib_normalized = contrib_normalized.round(2)
contrib_normalized.columns = [col.replace("ì ìˆ˜", "ì§€í‘œ") for col in new_columns]  # ì ìˆ˜ â†’ ì§€í‘œ


# ìˆ˜ì •: ë°±ë¶„ìœ¨ ë³€í™˜ëœ SHAP ì ìˆ˜ ì‚¬ìš©
df_with_scores = pd.concat([df.reset_index(drop=True), contrib_normalized], axis=1)


# ì €ì¥
df_with_scores.to_csv("ì „ì„¸ì˜ˆì¸¡_ì˜¤í”¼ìŠ¤í…”_SHAPì ìˆ˜ì¶”ê°€.csv", index=False)
print("âœ… SHAP ê¸°ì—¬ë„ ì»¬ëŸ¼ì´ ì¶”ê°€ëœ íŒŒì¼ ì €ì¥ ì™„ë£Œ: ì „ì„¸ì˜ˆì¸¡_ì˜¤í”¼ìŠ¤í…”_SHAPì ìˆ˜ì¶”ê°€.csv")

# 'ì „ì„¸_ì—¬ë¶€' ì»¬ëŸ¼ì— X ê°’ì´ ìˆëŠ” í–‰ ì œê±°
df_with_scores = df_with_scores[df_with_scores['ì „ì„¸_ì—¬ë¶€'].isna() | 
                                (df_with_scores['ì „ì„¸_ì—¬ë¶€'].astype(str).str.strip() == 'O')]

# ì „ì„¸ë§Œ ì €ì¥ (SHAP ì ìˆ˜ í¬í•¨ë¨)
df_with_scores.to_csv('ë‹¤ë°©_ì˜¤í”¼ìŠ¤í…”_DB_ìµœì¢…ë„£ê¸°.csv', index=False)



# 7. PostgreSQL ì—°ê²° ì„¤ì •
DB_URL = "postgresql://goldew:12345@project-db-campus.smhrd.com:3310/goldew"
pool = psycopg_pool.ConnectionPool(DB_URL, min_size=1, max_size=5)

def truncate_and_insert_and_update():
    # 1ë‹¨ê³„: ë°ì´í„° ì‚½ì…ìš© CSV
    df_insert = pd.read_csv("ë‹¤ë°©_ì˜¤í”¼ìŠ¤í…”_DB_ë„£ê¸°íŒŒì¼.csv")

    # 2ë‹¨ê³„: ì˜ˆì¸¡ê°’ ì—…ë°ì´íŠ¸ìš© CSV
    df_update = pd.read_csv("ë‹¤ë°©_ì˜¤í”¼ìŠ¤í…”_DB_ìµœì¢…ë„£ê¸°.csv")

    with pool.connection() as conn:
        cur = conn.cursor()
        try:
            # STEP 1: í…Œì´ë¸” ì´ˆê¸°í™”
            cur.execute("""
                TRUNCATE TABLE public.tb_property_detail, public.tb_property CASCADE;
            """)
            print("âœ… í…Œì´ë¸” TRUNCATE ì™„ë£Œ!")

            # STEP 2: INSERT
            for idx, row in df_insert.iterrows():
                property_id = idx + 1

                # tb_property ì‚½ì…
                cur.execute("""
                    INSERT INTO tb_property (
                        property_id, jeonse_price, address, area, current_floor,
                        immediate_move_in, listing_date
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s)
                """, (
                    property_id,
                    row['ì „ì„¸'],
                    str(row['ë§¤ë¬¼ì£¼ì†Œ']),
                    row['ì „ìš©ë©´ì '],
                    row['í•´ë‹¹ì¸µ'],
                    row['ì…ì£¼ê°€ëŠ¥ì¼'],
                    row['ìµœì´ˆë“±ë¡ì¼']
                ))

                # tb_property_detail ì‚½ì…
                cur.execute("""
                    INSERT INTO tb_property_detail (
                        property_id, jeonse_price, maintenance_fee, options, area, num_rooms,
                        num_bathrooms, has_elevator, parking_available, building_year,
                        building_usage, address, current_floor, immediate_move_in,
                        listing_date, room_type, building_floor, direction, agency_name
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                """, (
                    property_id,
                    row['ì „ì„¸'],
                    row['ê´€ë¦¬ë¹„'],
                    row['ì˜µì…˜ì •ë³´'],
                    row['ì „ìš©ë©´ì '],
                    row['ë°© ìˆ˜'],
                    row['ìš•ì‹¤ ìˆ˜'],
                    row['ì—˜ë¦¬ë² ì´í„°'],
                    row['ì£¼ì°¨ê°€ëŠ¥ì—¬ë¶€'],
                    row['ì‚¬ìš©ìŠ¹ì¸ì¼'],
                    row['ê±´ì¶•ë¬¼ìš©ë„'],
                    str(row['ë§¤ë¬¼ì£¼ì†Œ']),
                    row['í•´ë‹¹ì¸µ'],
                    row['ì…ì£¼ê°€ëŠ¥ì¼'],
                    row['ìµœì´ˆë“±ë¡ì¼'], 
                    row['ë°©ì¢…ë¥˜'],
                    row['ê±´ë¬¼ì¸µ'],
                    row['ë°©í–¥'],
                    row['ì¤‘ê°œì‚¬ë¬´ì†Œëª…']
                ))

            print("âœ… ë°ì´í„° ì‚½ì… ì™„ë£Œ!")

            # STEP 3: risk_level ë° estimated_jeonse_price ì—…ë°ì´íŠ¸
            for idx, row in df_update.iterrows():
                property_id = idx + 1
                risk_level = str(row["ì˜¤ì°¨ìœ¨(%)"])
                estimated_jeonse_price = str(row["ì˜ˆì¸¡ ì „ì„¸ê°€"])

                # tb_property ì—…ë°ì´íŠ¸
                cur.execute("""
                    UPDATE tb_property
                    SET 
                        risk_level = CASE WHEN risk_level IS NULL THEN %s ELSE risk_level END,
                        estimated_jeonse_price = CASE WHEN estimated_jeonse_price IS NULL THEN %s ELSE estimated_jeonse_price END
                    WHERE property_id = %s
                """, (risk_level, estimated_jeonse_price, property_id))

                # tb_property_detail ì—…ë°ì´íŠ¸
                cur.execute("""
                    UPDATE tb_property_detail
                    SET 
                        risk_level = CASE WHEN risk_level IS NULL THEN %s ELSE risk_level END,
                        estimated_jeonse_price = CASE WHEN estimated_jeonse_price IS NULL THEN %s ELSE estimated_jeonse_price END
                    WHERE property_id = %s
                """, (risk_level, estimated_jeonse_price, property_id))

            conn.commit()
            print("âœ… risk_level ë° estimated_jeonse_price ì—…ë°ì´íŠ¸ ì™„ë£Œ!")

        except Exception as e:
            conn.rollback()
            print("âŒ ì—ëŸ¬ ë°œìƒ:", e)
        finally:
            cur.close()

# ì‹¤í–‰
truncate_and_insert_and_update()

# PostgreSQL ì—°ê²° ì„¤ì •
DB_URL = "postgresql://goldew:12345@project-db-campus.smhrd.com:3310/goldew"
pool = psycopg_pool.ConnectionPool(DB_URL, min_size=1, max_size=5)

def truncate_and_insert_and_update():
    # 2ë‹¨ê³„: ì˜ˆì¸¡ê°’ ì—…ë°ì´íŠ¸ìš© CSV
    df_update = pd.read_csv("ë‹¤ë°©_ì˜¤í”¼ìŠ¤í…”_DB_ìµœì¢…ë„£ê¸°.csv")

    with pool.connection() as conn:
        cur = conn.cursor()
        try:
            # STEP 3: risk_level ë° estimated_jeonse_price ì—…ë°ì´íŠ¸
            for idx, row in df_update.iterrows():
                property_id = idx + 1
                log_building_age = str(row["log_ê±´ì¶•ì—°ì°¨ ì§€í‘œ"])
                log_area = str(row["log_ì „ìš©ë©´ì  ì§€í‘œ"])
                price_pyeong_score = str(row["í‰ê· í‰ë‹¹ê°€ê²©(ë§Œì›) ì§€í‘œ"])
                jeonse_pyeong_score = str(row["í‰ê· í‰ë‹¹ì „ì„¸ê°€(ë§Œì›) ì§€í‘œ"])
                population_score = str(row["ì´ì¸êµ¬ìˆ˜ ì§€í‘œ"])
                average_age_score = str(row["ë™ë³„í‰ê· ì—°ë ¹ ì§€í‘œ"])
                direction_score = str(row["ë°©í–¥ ì§€í‘œ"])    
                # tb_property_detail ì—…ë°ì´íŠ¸
                cur.execute("""
                    UPDATE tb_property_detail
                    SET 
                        log_building_age = CASE WHEN log_building_age IS NULL THEN %s ELSE log_building_age END,
                        log_area = CASE WHEN log_area IS NULL THEN %s ELSE log_area END,
                        price_pyeong_score = CASE WHEN price_pyeong_score IS NULL THEN %s ELSE price_pyeong_score END,
                        jeonse_pyeong_score = CASE WHEN jeonse_pyeong_score IS NULL THEN %s ELSE jeonse_pyeong_score END,
                        population_score = CASE WHEN population_score IS NULL THEN %s ELSE population_score END,
                        average_age_score = CASE WHEN average_age_score IS NULL THEN %s ELSE average_age_score END,
                        direction_score = CASE WHEN direction_score IS NULL THEN %s ELSE direction_score END
                    WHERE property_id = %s
                """, (log_building_age, log_area, price_pyeong_score, jeonse_pyeong_score,population_score,average_age_score,
                    direction_score, property_id))

            conn.commit()
            print("âœ… ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ ì™„ë£Œ!")

        except Exception as e:
            conn.rollback()
            print("âŒ ì—ëŸ¬ ë°œìƒ:", e)
        finally:
            cur.close()

# ì‹¤í–‰
truncate_and_insert_and_update()